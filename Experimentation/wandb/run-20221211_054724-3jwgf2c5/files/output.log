[34m[1mwandb[39m[22m: [33mWARNING[39m Calling wandb.login() after wandb.init() has no effect.
Could not locate the tokenizer configuration file, will try to use the model config instead.
loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /home/ecbm4040/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51
Model config GPT2Config {
  "_name_or_path": "gpt2",
  "activation_function": "gelu_new",
  "architectures": [
    "GPT2LMHeadModel"
  ],
  "attn_pdrop": 0.1,
  "bos_token_id": 50256,
  "embd_pdrop": 0.1,
  "eos_token_id": 50256,
  "initializer_range": 0.02,
  "layer_norm_epsilon": 1e-05,
  "model_type": "gpt2",
  "n_ctx": 1024,
  "n_embd": 768,
  "n_head": 12,
  "n_inner": null,
  "n_layer": 12,
  "n_positions": 1024,
  "reorder_and_upcast_attn": false,
  "resid_pdrop": 0.1,
  "scale_attn_by_inverse_layer_idx": false,
  "scale_attn_weights": true,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "cls_index",
  "summary_use_proj": true,
  "task_specific_params": {
    "text-generation": {
      "do_sample": true,
      "max_length": 50
    }
  },
  "transformers_version": "4.18.0",
  "use_cache": true,
  "vocab_size": 50257
}
loading file https://huggingface.co/gpt2/resolve/main/vocab.json from cache at /home/ecbm4040/.cache/huggingface/transformers/684fe667923972fb57f6b4dcb61a3c92763ad89882f3da5da9866baf14f2d60f.c7ed1f96aac49e745788faa77ba0a26a392643a50bb388b9c04ff469e555241f
loading file https://huggingface.co/gpt2/resolve/main/merges.txt from cache at /home/ecbm4040/.cache/huggingface/transformers/c0c761a63004025aeadd530c4c27b860ec4ecbe8a00531233de21d865a402598.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b
loading file https://huggingface.co/gpt2/resolve/main/tokenizer.json from cache at /home/ecbm4040/.cache/huggingface/transformers/16a2f78023c8dc511294f0c97b5e10fde3ef9889ad6d11ffaa2a00714e73926e.cf2d0ecb83b6df91b3dbb53f1d1e4c311578bfd3aa0e04934215a49bf9898df0
loading file https://huggingface.co/gpt2/resolve/main/added_tokens.json from cache at None
loading file https://huggingface.co/gpt2/resolve/main/special_tokens_map.json from cache at None
loading file https://huggingface.co/gpt2/resolve/main/tokenizer_config.json from cache at None
loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /home/ecbm4040/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51
Model config GPT2Config {
  "_name_or_path": "gpt2",
  "activation_function": "gelu_new",
  "architectures": [
    "GPT2LMHeadModel"
  ],
  "attn_pdrop": 0.1,
  "bos_token_id": 50256,
  "embd_pdrop": 0.1,
  "eos_token_id": 50256,
  "initializer_range": 0.02,
  "layer_norm_epsilon": 1e-05,
  "model_type": "gpt2",
  "n_ctx": 1024,
  "n_embd": 768,
  "n_head": 12,
  "n_inner": null,
  "n_layer": 12,
  "n_positions": 1024,
  "reorder_and_upcast_attn": false,
  "resid_pdrop": 0.1,
  "scale_attn_by_inverse_layer_idx": false,
  "scale_attn_weights": true,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "cls_index",
  "summary_use_proj": true,
  "task_specific_params": {
    "text-generation": {
      "do_sample": true,
      "max_length": 50
    }
  },
  "transformers_version": "4.18.0",
  "use_cache": true,
  "vocab_size": 50257
}
loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /home/ecbm4040/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51
Model config GPT2Config {
  "_name_or_path": "gpt2",
  "activation_function": "gelu_new",
  "architectures": [
    "GPT2LMHeadModel"
  ],
  "attn_pdrop": 0.1,
  "bos_token_id": 50256,
  "embd_pdrop": 0.1,
  "eos_token_id": 50256,
  "initializer_range": 0.02,
  "layer_norm_epsilon": 1e-05,
  "model_type": "gpt2",
  "n_ctx": 1024,
  "n_embd": 768,
  "n_head": 12,
  "n_inner": null,
  "n_layer": 12,
  "n_positions": 1024,
  "reorder_and_upcast_attn": false,
  "resid_pdrop": 0.1,
  "scale_attn_by_inverse_layer_idx": false,
  "scale_attn_weights": true,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "cls_index",
  "summary_use_proj": true,
  "task_specific_params": {
    "text-generation": {
      "do_sample": true,
      "max_length": 50
    }
  },
  "transformers_version": "4.18.0",
  "use_cache": true,
  "vocab_size": 50257
}
loading weights file https://huggingface.co/gpt2/resolve/main/pytorch_model.bin from cache at /home/ecbm4040/.cache/huggingface/transformers/752929ace039baa8ef70fe21cdf9ab9445773d20e733cf693d667982e210837e.323c769945a351daa25546176f8208b3004b6f563438a7603e7932bae9025925
All model checkpoint weights were used when initializing GPT2LMHeadModel.
All the weights of GPT2LMHeadModel were initialized from the model checkpoint at gpt2.
If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.
/home/ecbm4040/envTF24/lib/python3.6/site-packages/transformers/data/datasets/language_modeling.py:58: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py
  FutureWarning,
Creating features from dataset file at data
Token indices sequence length is longer than the specified maximum sequence length for this model (963361 > 1024). Running this sequence through the model will result in indexing errors
Saving features into cached file data/cached_lm_GPT2TokenizerFast_1024_impolite_hankgreen_50000_0.25_finalnum7746.txt [took 0.027 s]
env: WANDB_PROJECT=tweet_analysis
Collecting git+https://github.com/huggingface/transformers
  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-686dm05u
  Running command git clone -q https://github.com/huggingface/transformers /tmp/pip-req-build-686dm05u
  Resolved https://github.com/huggingface/transformers to commit 799cea64ac1029d66e9e58f18bc6f47892270723
  Installing build dependencies ... [?25ldone
[?25h  Getting requirements to build wheel ... [?25ldone
[?25h    Preparing wheel metadata ... [?25ldone
[31mERROR: Could not find a version that satisfies the requirement huggingface-hub<1.0,>=0.10.0 (from transformers) (from versions: 0.0.1, 0.0.2, 0.0.3rc1, 0.0.3rc2, 0.0.5, 0.0.6, 0.0.7, 0.0.8, 0.0.9, 0.0.10, 0.0.11, 0.0.12, 0.0.13, 0.0.14, 0.0.15, 0.0.16, 0.0.17, 0.0.18, 0.0.19, 0.1.0, 0.1.1, 0.1.2, 0.2.0, 0.2.1, 0.4.0)
[31mERROR: No matching distribution found for huggingface-hub<1.0,>=0.10.0
[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.
[33mYou should consider upgrading via the '/home/ecbm4040/envTF24/bin/python3 -m pip install --upgrade pip' command.
[?25hRequirement already satisfied: wandb in /home/ecbm4040/envTF24/lib/python3.6/site-packages (0.13.6)
Requirement already satisfied: dataclasses in /home/ecbm4040/envTF24/lib/python3.6/site-packages (from wandb) (0.8)
Requirement already satisfied: pathtools in /home/ecbm4040/envTF24/lib/python3.6/site-packages (from wandb) (0.1.2)
Requirement already satisfied: requests<3,>=2.0.0 in /home/ecbm4040/envTF24/lib/python3.6/site-packages (from wandb) (2.26.0)
Requirement already satisfied: GitPython>=1.0.0 in /home/ecbm4040/envTF24/lib/python3.6/site-packages (from wandb) (3.1.18)
Requirement already satisfied: shortuuid>=0.5.0 in /home/ecbm4040/envTF24/lib/python3.6/site-packages (from wandb) (1.0.11)
Requirement already satisfied: promise<3,>=2.0 in /home/ecbm4040/envTF24/lib/python3.6/site-packages (from wandb) (2.3)
Requirement already satisfied: sentry-sdk>=1.0.0 in /home/ecbm4040/envTF24/lib/python3.6/site-packages (from wandb) (1.11.1)
Requirement already satisfied: setproctitle in /home/ecbm4040/envTF24/lib/python3.6/site-packages (from wandb) (1.2.3)
Requirement already satisfied: protobuf!=4.21.0,<5,>=3.12.0 in /home/ecbm4040/envTF24/lib/python3.6/site-packages (from wandb) (3.17.3)
Requirement already satisfied: Click!=8.0.0,>=7.0 in /home/ecbm4040/envTF24/lib/python3.6/site-packages (from wandb) (8.0.4)
Requirement already satisfied: PyYAML in /home/ecbm4040/envTF24/lib/python3.6/site-packages (from wandb) (6.0)
Requirement already satisfied: psutil>=5.0.0 in /home/ecbm4040/envTF24/lib/python3.6/site-packages (from wandb) (5.9.4)
Requirement already satisfied: docker-pycreds>=0.4.0 in /home/ecbm4040/envTF24/lib/python3.6/site-packages (from wandb) (0.4.0)
Requirement already satisfied: setuptools in /home/ecbm4040/envTF24/lib/python3.6/site-packages (from wandb) (58.0.2)
Requirement already satisfied: importlib-metadata in /home/ecbm4040/envTF24/lib/python3.6/site-packages (from Click!=8.0.0,>=7.0->wandb) (4.8.1)
Requirement already satisfied: six>=1.4.0 in /home/ecbm4040/envTF24/lib/python3.6/site-packages (from docker-pycreds>=0.4.0->wandb) (1.15.0)
Requirement already satisfied: typing-extensions>=3.7.4.0 in /home/ecbm4040/envTF24/lib/python3.6/site-packages (from GitPython>=1.0.0->wandb) (3.7.4.3)
Requirement already satisfied: gitdb<5,>=4.0.1 in /home/ecbm4040/envTF24/lib/python3.6/site-packages (from GitPython>=1.0.0->wandb) (4.0.9)
Requirement already satisfied: smmap<6,>=3.0.1 in /home/ecbm4040/envTF24/lib/python3.6/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)
Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ecbm4040/envTF24/lib/python3.6/site-packages (from requests<3,>=2.0.0->wandb) (2.0.4)
Requirement already satisfied: idna<4,>=2.5 in /home/ecbm4040/envTF24/lib/python3.6/site-packages (from requests<3,>=2.0.0->wandb) (3.2)
Requirement already satisfied: certifi>=2017.4.17 in /home/ecbm4040/envTF24/lib/python3.6/site-packages (from requests<3,>=2.0.0->wandb) (2021.5.30)
Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ecbm4040/envTF24/lib/python3.6/site-packages (from requests<3,>=2.0.0->wandb) (1.26.13)
Requirement already satisfied: zipp>=0.5 in /home/ecbm4040/envTF24/lib/python3.6/site-packages (from importlib-metadata->Click!=8.0.0,>=7.0->wandb) (3.5.0)
[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.
[33mYou should consider upgrading via the '/home/ecbm4040/envTF24/bin/python3 -m pip install --upgrade pip' command.